#!/bin/bash

# PeteOllama Agent Startup Script for RunPod
# Optimized for memory and disk space management

set -e

echo "ğŸš€ Starting PeteOllama Agent Setup..."

# Memory and disk optimization
echo "ğŸ§¹ Clearing cache and optimizing memory..."
rm -rf /root/.cache/uv 2>/dev/null || true
rm -rf /root/.cache/pip 2>/dev/null || true
rm -rf /tmp/* 2>/dev/null || true

# Move cache to persistent volume
mkdir -p /workspace/cache
if [ ! -L /root/.cache ]; then
    ln -sf /workspace/cache /root/.cache
fi

# Set environment variables
export PATH="$PATH:/usr/local/bin"
export OLLAMA_HOST=0.0.0.0
export OLLAMA_ORIGINS=*
export OLLAMA_MODELS=/workspace/.ollama/models
export OLLAMA_BASE_URL=http://localhost:11434
export DEFAULT_MODEL=peteollama:property-manager-v0.0.1
export PROXY_PORT=8001

# Create necessary directories
mkdir -p /workspace/.ollama/models
mkdir -p /workspace/cache

# Install system dependencies
echo "ğŸ“¦ Installing system dependencies..."
apt-get update -qq
apt-get install -y tree xsel curl git

# Install uv if not present
if ! command -v uv &> /dev/null; then
    echo "ğŸ“¦ Installing uv..."
    curl -Ls https://astral.sh/uv/install.sh | sh
fi

# Change to repo directory and pull latest changes
echo "ğŸ”„ Checking for latest code updates..."
cd /workspace/Pete_ollama_agent
if [ -d ".git" ]; then
    echo "ğŸ“¡ Pulling latest changes from GitHub..."
    git fetch origin main
    git reset --hard origin/main --quiet
    git clean -fd --quiet
    echo "âœ… Updated to latest version"
else
    echo "âš ï¸ Not a git repository - skipping auto-update"
fi

# Kill any existing Ollama processes
echo "ğŸ”„ Stopping existing Ollama processes..."
pkill ollama 2>/dev/null || true
pkill -f uvicorn 2>/dev/null || true
pkill -f "src/main.py" 2>/dev/null || true
sleep 2

# Install Ollama
echo "ğŸ¤– Installing Ollama..."
curl -fsSL https://ollama.com/install.sh | sh

# Start Ollama with optimized settings
echo "ğŸš€ Starting Ollama..."
ollama serve &
OLLAMA_PID=$!

# Wait for Ollama to start
echo "â³ Waiting for Ollama to start..."
sleep 10

# Pull base models (only if not already present)
echo "ğŸ“¥ Checking for base models..."
if ! ollama list | grep -q "llama3:latest"; then
    echo "ğŸ“¥ Pulling llama3:latest..."
    ollama pull llama3:latest
fi

if ! ollama list | grep -q "qwen3:30b"; then
    echo "ğŸ“¥ Pulling qwen3:30b..."
    ollama pull qwen3:30b
fi

# Create custom model if not exists
echo "ğŸ”§ Setting up custom model..."
if ! ollama list | grep -q "peteollama:property-manager-v0.0.1"; then
    echo "ğŸ“¥ Creating peteollama:property-manager-v0.0.1..."
    ollama create peteollama:property-manager-v0.0.1 -f models/Modelfile.enhanced
fi

# Install Python dependencies
echo "ğŸ Installing Python dependencies..."
uv sync

# Create database
echo "ğŸ—„ï¸ Setting up database..."
python src/virtual_jamie_extractor.py

# Start the application
echo "ğŸŒ Starting PeteOllama application..."
uv run python src/main.py &

# Wait for services to start
sleep 5

# Show status
echo "ğŸ“Š System Status:"
echo "=================="
df -h /workspace
echo ""
free -h
echo ""
ollama list
echo ""
echo "âœ… PeteOllama Agent is ready!"
echo "ğŸŒ Frontend: http://localhost:8000"
echo "ğŸ”— Proxy: http://localhost:8001"
echo "ğŸ¤– Ollama: http://localhost:11434"

# Keep script running
wait
