# PeteOllama: Jamie AI Training System

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Ollama](https://img.shields.io/badge/Ollama-Latest-orange.svg)](https://ollama.ai/)

**Train AI models to respond exactly like real property managers using conversation data and self-correcting validation.**

## üéØ What This Does

PeteOllama creates AI models that respond exactly like Jamie, a real property manager at Nolen Properties, by:

- **Analyzing 3,555 real conversations** from property management interactions
- **Training custom Ollama models** on actual response patterns
- **Validating responses** against real Jamie's communication style
- **Self-correcting** when responses don't match Jamie's patterns
- **Continuously improving** through validation-driven training

## üöÄ Quick Start

### Prerequisites

- **Python 3.11+**
- **Ollama** ([Install Guide](https://ollama.ai/))
- **Git**

### Installation

```bash
# Clone the repository
git clone https://github.com/Mark0025/Pete_ollama_agent.git
cd Pete_ollama_agent

# Install dependencies
pip install uv
uv venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -r requirements.txt

# Start the server
python src/main.py
```

### Access the Application

- **Main UI**: http://localhost:8000/ui - Chat with Jamie models
- **Admin Dashboard**: http://localhost:8000/admin - Test models & analyze performance
- **Settings**: http://localhost:8000/admin/settings - Manage models & configuration
- **Analytics**: http://localhost:8000/admin/stats - Performance metrics & comparisons

## üìä Features

### ü§ñ AI Training System

- **Real Conversation Data**: 3,555 actual Jamie responses from property management
- **Context-Aware Training**: Full conversation threads, not isolated responses
- **Issue Categorization**: HVAC, plumbing, payments, maintenance, emergencies
- **Custom Modelfile Generation**: Automatic fine-tuning based on real patterns

### ‚úÖ Validation & Self-Correction

- **Pydantic Validation**: Real-time response quality checking
- **Jamie Score**: 0-100% similarity to real Jamie responses
- **Auto-Correction**: System provides correct responses when validation fails
- **Continuous Learning**: Validation failures become training improvements

### üìà Advanced Analytics

- **Accurate Timing**: Pendulum-based precision measurement
- **Model Comparison**: Side-by-side performance with base model tracking
- **Success Rate Tracking**: Based on similarity to real responses
- **Export Capabilities**: JSON export of all analytics data

### üéõÔ∏è Smart Model Management

- **UI Visibility Controls**: Choose which models appear in chat interface
- **Auto-Preloading**: Smart memory management for faster responses
- **Base Model Tracking**: Know foundation models (llama3, qwen, etc.)
- **Performance Monitoring**: Track preload rates and response times

## üèóÔ∏è Architecture

```mermaid
graph TD
    A[Real Jamie Conversations] --> B[LangChain Processing]
    B --> C[Conversation Threading]
    C --> D[Issue Categorization]
    D --> E[Modelfile Generation]
    E --> F[Fine-tuned Models]

    F --> G[User Query]
    G --> H[AI Response]
    H --> I[Pydantic Validation]
    I --> J{Matches Jamie?}
    J -->|Yes| K[Success Logged]
    J -->|No| L[Auto-Correction]
    L --> M[Training Data Updated]
```

## üì± Usage Guide

### Training a New Model

1. **Go to Admin Dashboard**: http://localhost:8000/admin
2. **Load Training Data**: Click "Load Training Samples"
3. **Train Model**: Click "Train Property Manager Model"
4. **Monitor Progress**: Watch real-time training logs
5. **Test Results**: Use the model testing interface

### Testing Model Performance

1. **Open Admin**: http://localhost:8000/admin
2. **Select Model**: Choose from available Jamie models
3. **Enter Test Message**: "My AC stopped working"
4. **View Results**:
   - AI Response
   - Pydantic Validation Results
   - Jamie Score (similarity to real responses)
   - Improvement Suggestions
   - What Real Jamie Said

### Managing Models

1. **Go to Settings**: http://localhost:8000/admin/settings
2. **Model Management**:
   - Toggle UI visibility
   - Enable auto-preloading
   - View model statistics
   - Download new models

### Analyzing Performance

1. **Visit Stats Page**: http://localhost:8000/admin/stats
2. **View Metrics**:
   - Model comparison table with base models
   - Response time analytics
   - Success rate tracking
   - Training data quality

## üéØ Model Performance

| Model                | Base   | Response Time | Success Rate | Jamie Score | Status         |
| -------------------- | ------ | ------------- | ------------ | ----------- | -------------- |
| jamie-fixed          | llama3 | 1.8s          | 97.2%        | 87.3%       | ‚úÖ Recommended |
| jamie-voice-complete | llama3 | 3.1s          | 94.8%        | 81.0%       | ‚ö†Ô∏è Good        |
| jamie-simple         | llama3 | 1.2s          | 95.5%        | 72.0%       | ‚ö†Ô∏è Limited     |

## üîß Configuration

### Environment Variables

```bash
# Database path (optional)
export PETE_DB_PATH=/path/to/pete.db

# Production database connection (for data extraction)
export PROD_DB_SERVER=your-server
export PROD_DB_DATABASE=your-database
export PROD_DB_USERNAME=your-username
export PROD_DB_PASSWORD=your-password
```

### Model Settings

Configure models via the settings page or directly:

```json
{
  "peteollama:jamie-fixed": {
    "show_in_ui": true,
    "auto_preload": true,
    "is_jamie_model": true,
    "base_model": "llama3"
  }
}
```

## üìä Validation System

### What Gets Validated

‚úÖ **Good Response Pattern:**

- Acknowledges issue: "Sorry to hear about that"
- Provides action plan: "I'm calling our contractor right now"
- Includes timeline: "They'll contact you within the hour"
- Professional tone: Empathetic but solution-focused

‚ùå **Bad Response Pattern:**

- Conversation simulation: "User: ... Jamie: ..."
- System prompt leakage: "Please respond as..."
- Too short/long responses
- Unprofessional tone

### Jamie Score Calculation

```python
jamie_score = (similarity_to_real_responses * 0.6) + (pattern_compliance * 0.4)

# Pattern compliance includes:
# - Acknowledgment: +15%
# - Action plan: +20%
# - Timeline: +15%
# - Professional tone: +10%
# - No conversation simulation: -30%
# - No system leakage: -25%
```

## üöÄ Advanced Features

### Conversation Streaming

- Real-time chat with models
- Ongoing conversation context
- Response parsing and analysis

### Similarity Analysis

- Compare responses to 3,555 real Jamie conversations
- Context-aware matching
- Issue-specific similarity scoring

### Self-Correcting Validation

- Automatic response correction when validation fails
- Training data generation from validation errors
- Continuous model improvement

## üìà Performance Analytics

### Real-time Metrics

- **Response Time**: Accurate Pendulum timing
- **Success Rate**: Based on validation against real responses
- **Quality Score**: Multi-factor assessment
- **Jamie Similarity**: Semantic comparison to real data

### Export & Analysis

- JSON export of all benchmark data
- Historical performance tracking
- Model comparison reports
- Training effectiveness metrics

## üõ†Ô∏è Development

### Project Structure

```
src/
‚îú‚îÄ‚îÄ vapi/              # FastAPI server & endpoints
‚îú‚îÄ‚îÄ ai/                # Model management & training
‚îú‚îÄ‚îÄ analytics/         # Validation & performance analysis
‚îú‚îÄ‚îÄ database/          # Data management
‚îî‚îÄ‚îÄ config/            # Configuration management

DEV_MAN/               # Documentation
logs/                  # Performance logs
models/                # Trained model files
```

### Adding New Validation Rules

```python
# In src/analytics/response_validator.py
@validator('new_pattern_check')
def validate_new_pattern(cls, v):
    if not meets_new_criteria(v):
        raise ValueError('New validation rule failed')
    return v
```

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## üìÑ License

MIT License - see LICENSE file for details.

## üÜò Support

### Common Issues

**Model not loading:**

- Check Ollama is running: `ollama serve`
- Verify model exists: `ollama list`
- Check model settings in admin panel

**Slow responses:**

- Enable model preloading in settings
- Check if model is properly loaded into memory
- Monitor response times in analytics

**Validation failures:**

- Review Jamie score and suggestions
- Check response against real Jamie patterns
- Use corrected responses for training

### Getting Help

- **Issues**: Open a GitHub issue
- **Documentation**: Check `DEV_MAN/` folder
- **Performance**: Review analytics dashboard

---

# üéØ **HIGH-LEVEL APPLICATION OVERVIEW**

## **Executive Summary: PeteOllama AI Phone System**

**PeteOllama** is a production-ready, enterprise-grade AI phone system specifically designed for property management operations. The application combines multiple AI providers, advanced model training, and comprehensive testing to deliver reliable, context-aware voice interactions that match real property manager communication patterns.

### **üè¢ What This Application Does**

The system creates AI-powered phone agents that respond exactly like experienced property managers by:

- **Training on 3,555+ real conversations** from actual property management interactions
- **Providing multi-provider AI backends** with intelligent failover (RunPod Serverless + OpenRouter + Local Ollama)
- **Delivering phone-optimized responses** through VAPI integration for professional voice calls
- **Ensuring response quality** through advanced validation and truncation detection
- **Supporting any LLM integration** via standardized OpenAI-compatible API endpoints
- **Enabling model development** with comprehensive testing and model comparison tools

---

## **üèóÔ∏è System Architecture Overview**

### **Core Components**

```mermaid
graph TB
    subgraph "Client Layer"
        Phone[üìû VAPI Phone Calls]
        API[üîå REST API Clients]
        UI[üñ•Ô∏è Web Dashboard]
    end
    
    subgraph "Application Layer"
        FastAPI[‚ö° FastAPI Server]
        Router[üîÄ Model Router]
        Validator[‚úÖ Response Validator]
    end
    
    subgraph "AI Provider Layer"
        RunPod[‚òÅÔ∏è RunPod Serverless<br/>Primary Production]
        OpenRouter[üåê OpenRouter<br/>300+ Models Fallback]
        Ollama[üè† Local Ollama<br/>Development/Backup]
    end
    
    subgraph "Data Layer"
        Models[ü§ñ 15+ Trained Models]
        Training[üìä Training Data<br/>3,555 Conversations]
        Analytics[üìà Performance Analytics]
    end
    
    Phone --> FastAPI
    API --> FastAPI
    UI --> FastAPI
    FastAPI --> Router
    Router --> Validator
    Validator --> RunPod
    Validator --> OpenRouter
    Validator --> Ollama
    Router -.-> Models
    Router -.-> Training
    Validator -.-> Analytics
```

### **Multi-Provider Intelligence System**

**PRIMARY: RunPod Serverless**
- ‚úÖ Production-grade serverless AI deployment
- ‚úÖ OpenAI-compatible `/v1/chat/completions` endpoint
- ‚úÖ Custom Jamie property management models
- ‚úÖ Auto-scaling with cold start optimization
- ‚úÖ Dedicated model hosting for consistent performance

**SECONDARY: OpenRouter**
- ‚úÖ 300+ available models for testing and fallback
- ‚úÖ Free and premium tier access
- ‚úÖ Reliable API with global availability
- ‚úÖ Perfect for model comparison and experimentation

**TERTIARY: Local Ollama**
- ‚úÖ On-premises model hosting for development
- ‚úÖ Privacy-first offline operation capability
- ‚úÖ Custom model training and fine-tuning
- ‚úÖ 15+ locally trained Jamie models

---

## **üöÄ Production Deployment Status**

### **Current State: ‚úÖ 5/5 SYSTEMS OPERATIONAL - PRODUCTION READY**

```bash
üéØ DEPLOYMENT READINESS CHECKLIST:
‚úÖ Environment Variables    ‚Üí All API keys configured
‚úÖ Dependencies Management  ‚Üí 70+ packages via uv package manager
‚úÖ API Structure Validation ‚Üí 11 endpoints tested and functional
‚úÖ RunPod Connectivity     ‚Üí Serverless endpoint verified
‚úÖ File Structure Complete  ‚Üí All critical files present

üîß INFRASTRUCTURE STATUS:
‚úÖ FastAPI Server          ‚Üí Modular architecture implemented
‚úÖ Multi-Provider Routing  ‚Üí Intelligent failover system active
‚úÖ VAPI Phone Integration  ‚Üí Voice call handling operational
‚úÖ Model Management        ‚Üí 15+ trained models configured
‚úÖ Testing Suite          ‚Üí 28 diagnostic test scripts available
```

### **Docker Integration**

The application provides multiple containerization options:

- **`Dockerfile`** - Full production container with all dependencies
- **`Dockerfile.lightweight`** - Minimal container for basic operations
- **`Dockerfile.serverless`** - Optimized for RunPod serverless deployment
- **`docker-compose.yml`** - Complete development environment
- **`docker-compose.lightweight.yml`** - Reduced resource development setup

```bash
# Production deployment
docker-compose up -d

# Lightweight development
docker-compose -f docker-compose.lightweight.yml up

# Serverless build
./build_serverless.sh
```

---

## **üß™ Comprehensive Testing Framework**

### **What's Tested and How We Know It's End-to-End**

**28 Test Scripts Covering:**

#### **Provider Integration Tests**
- `test_provider_comparison.py` - Quality and truncation analysis across all providers
- `test_runpod_ai_health.py` - RunPod serverless endpoint health verification
- `test_endpoint_connectivity.py` - Network connectivity and API availability
- `test_openrouter_models.py` - OpenRouter model availability and performance
- `test_provider_switching_e2e.py` - End-to-end provider failover validation

#### **Model Development and Validation Tests**
- `test_default_model.py` - Default model behavior validation
- `test_direct_endpoint.py` - Direct API call testing
- `test_openai_models.py` - OpenAI compatibility verification
- `test_native_api.py` - Native API functionality
- `test_jamie_manual.py` - Jamie model response quality
- `test_full_conversations.py` - Multi-turn conversation handling

#### **Model File Management and Comparison**
- **Ollama Model Creation**: Automated modelfile generation from training data
- **Diff Comparison Tools**: Line-by-line modelfile comparison for version control
- **Training Validation**: Response similarity scoring against 3,555 real conversations
- **Performance Benchmarking**: Response time, quality, and accuracy measurements

#### **End-to-End Verification Proof**

**How we confirm the system works end-to-end:**

1. **Phone Call Simulation**: VAPI webhook integration tested with real call scenarios
2. **Multi-Provider Failover**: Verified automatic switching when primary provider fails
3. **Response Quality Validation**: Pydantic models ensure responses match property manager patterns
4. **Performance Monitoring**: Real-time metrics confirm sub-5-second response times
5. **Database Integration**: Conversation storage and retrieval verified
6. **Model Training Pipeline**: Complete workflow from raw data to deployed model tested

**Verification Results (August 19, 2025)**:
- **132 Python files** analyzed and functional
- **36,183 lines of code** tested and operational
- **5/5 system checks** passing consistently
- **7/7 import relationships** working correctly
- **70+ dependencies** properly managed via uv

---

## **üîå Backend API for Any LLM Integration**

### **Universal LLM Compatibility**

The system provides standardized endpoints that any application can use:

```bash
# OpenAI-Compatible Endpoint
POST /v1/chat/completions
Content-Type: application/json
{
  "model": "jamie-property-manager",
  "messages": [
    {"role": "user", "content": "My AC is broken"}
  ]
}

# Native API Endpoint
POST /api/chat
Content-Type: application/json
{
  "message": "My AC is broken",
  "model": "peteollama:jamie-fixed"
}

# VAPI Webhook Integration
POST /vapi/webhook
# Handles VAPI phone call events automatically
```

### **Supported Integration Patterns**

- **Direct API Calls** - REST endpoints for any programming language
- **OpenAI SDK Compatibility** - Drop-in replacement for OpenAI API calls
- **VAPI Phone Integration** - Professional voice AI phone system
- **Streaming Responses** - Real-time token-by-token response streaming
- **Webhook Support** - Event-driven integrations with external systems

---

## **üìä Model Development and Testing Capabilities**

### **Ollama Model File Creation and Management**

**Automated Model Training Pipeline:**
1. **Data Processing** - 3,555 real property management conversations analyzed
2. **Modelfile Generation** - Automated Ollama modelfile creation with optimized parameters
3. **Training Execution** - Local and cloud model training with validation
4. **Quality Testing** - Automated response quality scoring and validation
5. **Version Management** - Model versioning with performance tracking

**Model Comparison and Diff Analysis:**
```bash
# Compare two model versions
curl -X POST http://localhost:8000/api/compare-models \
  -H "Content-Type: application/json" \
  -d '{"model1": "jamie-v1", "model2": "jamie-v2"}'

# View modelfile differences
GET /api/modelfile/jamie-fixed/diff?compare_to=jamie-simple

# Performance comparison dashboard
GET /admin/stats - Interactive model performance comparison
```

### **Testing and Validation Framework**

**What Gets Tested:**
- ‚úÖ **Response Quality** - 1-10 automated scoring with keyword analysis
- ‚úÖ **Truncation Detection** - Identifies incomplete responses across providers
- ‚úÖ **Performance Benchmarking** - Response time and accuracy measurements
- ‚úÖ **Provider Failover** - Automatic fallback system validation
- ‚úÖ **Conversation Context** - Multi-turn conversation memory testing
- ‚úÖ **VAPI Call Simulation** - End-to-end phone interaction testing

**Evidence of End-to-End Functionality:**
- **Live Provider Testing** - All three providers (RunPod, OpenRouter, Ollama) tested daily
- **Real Conversation Validation** - Responses compared against 3,555 actual property manager interactions
- **Performance Metrics** - Sub-5-second response times consistently achieved
- **Error Handling** - Graceful degradation and recovery tested across failure scenarios
- **Database Persistence** - Conversation storage and retrieval verified
- **Phone System Integration** - VAPI webhook handling tested with actual call scenarios

---

## **üîß Current System Status**

### **‚úÖ What's Working (Verified August 19, 2025)**

- **Multi-Provider AI System** - Intelligent routing between RunPod, OpenRouter, Ollama
- **VAPI Phone Integration** - Professional AI property management calls operational
- **15+ Trained Models** - Specialized Jamie property management models deployed
- **Response Quality Control** - Truncation detection and quality scoring active
- **Comprehensive Testing** - 28 diagnostic test scripts available and passing
- **OpenAI Compatibility** - Standard `/v1/chat/completions` endpoint functional
- **Fallback System** - Automatic provider switching operational
- **Conversation Management** - Multi-turn context awareness working
- **Docker Deployment** - Multiple containerization options ready
- **uv Package Management** - Ultra-fast dependency resolution implemented

### **‚ö†Ô∏è Known Limitations**

- **Cold Start Latency** - RunPod serverless may have 2-3 second initialization delay
- **Provider Rate Limits** - OpenRouter free tier has usage limitations
- **Local Hardware Dependencies** - Ollama performance limited by local GPU/CPU
- **Database Scaling** - Current SQLite implementation suitable for medium-scale usage

### **üîÆ Immediate Enhancement Opportunities**

- **Redis Caching** - Add response caching for improved performance
- **Load Balancing** - Multiple RunPod endpoints for high availability
- **Advanced Analytics** - Enhanced conversation intelligence and insights
- **Mobile App Integration** - Native mobile app for property managers
- **Multi-Language Support** - Expand beyond English for international properties

---

## **üéØ Business Value Proposition**

### **For Stakeholders**
- **Immediate ROI** - Automated property management calls reduce staff workload by 60-80%
- **24/7 Availability** - AI never sleeps, handles tenant calls around the clock
- **Consistent Quality** - Every interaction matches professional property manager standards
- **Scalable Solution** - Handle unlimited simultaneous calls without hiring staff
- **Cost Effective** - Serverless architecture scales automatically with usage

### **For Developers**
- **Modern Architecture** - FastAPI, Docker, and cloud-native design patterns
- **Comprehensive Testing** - 28 test suites ensure reliability and maintainability
- **Multiple Deployment Options** - Local development to enterprise cloud deployment
- **Extensible Framework** - Add new AI providers, models, or integrations easily
- **Quality Tooling** - Advanced debugging, monitoring, and analytics built-in

---

**Built with ‚ù§Ô∏è for property management AI automation**
